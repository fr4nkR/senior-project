{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77523e84",
   "metadata": {},
   "source": [
    "# Owner #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa7508",
   "metadata": {},
   "source": [
    "## Initital set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages that allow for image tranformations and transform to Tensor\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "import torch\n",
    "import os\n",
    "import imageio\n",
    "import cv2 as cv\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the directory and transform to tensor\n",
    "path = \"/Users/danielcastillo/Documents/senior-project/Data/CATS_DOGS/test/CAT\"\n",
    "\n",
    "#transform the images to a list Tensors\n",
    "transform(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new duet session\n",
    "import syft as sy\n",
    "sy.VERBOSE = False\n",
    "duet = sy.duet(loopback = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01a467",
   "metadata": {},
   "source": [
    "## Wait! Run Data Scientist till Checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e01f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#change the list of tensors into a single tensor\n",
    "stacked = torch.stack(arr)\n",
    "#change the tensor data type from Float64 to Float32\n",
    "stacked = stacked.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign a tag to the image\n",
    "image = stacked.tag(\"test cats\")\n",
    "#assign a description\n",
    "image = stacked.describe(\"tensor data\")\n",
    "\n",
    "#send the pointer through duet\n",
    "image_ptr = image.send(duet, searchable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all the pointers currently in the duet store\n",
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a hadler to accept any request with the name \"loss\"\n",
    "duet.requests.add_handler(\n",
    "    name=\"loss\",\n",
    "    action=\"accept\",\n",
    "    timeout_secs=-1,  # no timeout\n",
    "    print_local=True  # print the result in your notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195273a",
   "metadata": {},
   "source": [
    "# Definition for transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48cede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(path):\n",
    "    #declare a new list\n",
    "    arr = []\n",
    "    \n",
    "    tqdm().pandas()\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for pic in tqdm(os.scandir(path)):\n",
    "        #control the number of images to transform\n",
    "        if i < 100:\n",
    "            #check if file is of valid type \n",
    "            if (pic.path.endswith(\".jpeg\") or pic.path.endswith(\".jpg\")) and pic.is_file():\n",
    "                #read the image\n",
    "                picture = cv.imread(pic.path)\n",
    "                if(type(picture) != None):\n",
    "                    #resize the picture to 10 x 10\n",
    "                    picture = resize(picture, (10,10), mode='constant', anti_aliasing=True)\n",
    "                    #change the picture to gray scale\n",
    "                    picture = rgb2gray(picture)\n",
    "                    #transform the picture to a tensor\n",
    "                    Tensor = torch.tensor(picture)\n",
    "                    Tensor = Tensor.flatten()\n",
    "                    #append the tensor to the list\n",
    "                    arr.append(Tensor)\n",
    "                else:\n",
    "                    #this means that the picture was NoneType\n",
    "                    print(\"not added to the list: \", i)\n",
    "                    #skip iteration\n",
    "                    continue\n",
    "        i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cd2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
